{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b368963",
   "metadata": {},
   "source": [
    "# Task 4 Fine-Tuning Implementation\n",
    "\n",
    "This notebook contains the fine-tunning implementation for generating new class-conditional images of the selected damage type. In addition, the notebook is used on Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e0868",
   "metadata": {},
   "source": [
    "## Step 1: Upload Dataset\n",
    "\n",
    "**Option A: Upload via Colab**\n",
    "\n",
    "Run the cell below and upload the `bottle` folder from your local machine:\n",
    "`Defect_Spectrum/DS-MVTec/bottle/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17089cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Direct upload\n",
    "import os\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "# Create directory structure\n",
    "os.makedirs('Defect_Spectrum/DS-MVTec/bottle/image', exist_ok=True)\n",
    "\n",
    "print(\"Please upload your bottle dataset as a zip file...\")\n",
    "print(\"Create a zip of: Defect_Spectrum/DS-MVTec/bottle/\")\n",
    "print(\"(Should contain image/ subfolder with damage type subdirectories)\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "for filename in uploaded.keys():\n",
    "    if filename.endswith('.zip'):\n",
    "        shutil.unpack_archive(filename, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a187ac",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd97ae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q diffusers transformers accelerate peft safetensors\n",
    "print(\"Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a1b69d",
   "metadata": {},
   "source": [
    "## Step 3: Dataset Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb62ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, Optional, List\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class LocalDatasetConfig:\n",
    "    \"\"\"Configuration for local DefectSpectrum dataset loading.\"\"\"\n",
    "    resolution: int = 512\n",
    "    augment: bool = True\n",
    "    seed: int = 0\n",
    "    normalize_to_neg1_pos1: bool = True\n",
    "    \n",
    "    load_masks: bool = False\n",
    "    dataset_sources: Optional[List[str]] = None\n",
    "    product_classes: Optional[List[str]] = None\n",
    "    damage_types: Optional[List[str]] = None\n",
    "    max_samples_per_damage_type: Optional[int] = None\n",
    "    damage_type_to_class_id: Optional[Dict[str, int]] = None\n",
    "\n",
    "\n",
    "class DefectSpectrumLocalDataset(Dataset[Dict[str, Any]]):\n",
    "    \"\"\"PyTorch Dataset for local DefectSpectrum folder structure.\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir: str, cfg: LocalDatasetConfig):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.cfg = cfg\n",
    "        self.samples = self._scan_directory()\n",
    "    \n",
    "    def _scan_directory(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Scan directory for image files.\"\"\"\n",
    "        samples = []\n",
    "        \n",
    "        for dataset_dir in self.root_dir.iterdir():\n",
    "            if not dataset_dir.is_dir():\n",
    "                continue\n",
    "            \n",
    "            dataset_source = dataset_dir.name\n",
    "            if self.cfg.dataset_sources and dataset_source not in self.cfg.dataset_sources:\n",
    "                continue\n",
    "            \n",
    "            for product_dir in dataset_dir.iterdir():\n",
    "                if not product_dir.is_dir():\n",
    "                    continue\n",
    "                \n",
    "                product_class = product_dir.name\n",
    "                if self.cfg.product_classes and product_class not in self.cfg.product_classes:\n",
    "                    continue\n",
    "                \n",
    "                image_dir = product_dir / \"image\"\n",
    "                if not image_dir.exists():\n",
    "                    continue\n",
    "                \n",
    "                for damage_type_dir in image_dir.iterdir():\n",
    "                    if not damage_type_dir.is_dir():\n",
    "                        continue\n",
    "                    \n",
    "                    damage_type = damage_type_dir.name\n",
    "                    if self.cfg.damage_types and damage_type not in self.cfg.damage_types:\n",
    "                        continue\n",
    "                    \n",
    "                    damage_samples = []\n",
    "                    for img_path in sorted(damage_type_dir.glob(\"*\")):\n",
    "                        if img_path.suffix.lower() in [\".png\", \".jpg\", \".jpeg\"]:\n",
    "                            sample = {\n",
    "                                \"image_path\": str(img_path),\n",
    "                                \"dataset_source\": dataset_source,\n",
    "                                \"product_class\": product_class,\n",
    "                                \"damage_type\": damage_type,\n",
    "                                \"filename\": img_path.name,\n",
    "                            }\n",
    "                            damage_samples.append(sample)\n",
    "                    \n",
    "                    if self.cfg.max_samples_per_damage_type:\n",
    "                        damage_samples = damage_samples[:self.cfg.max_samples_per_damage_type]\n",
    "                    \n",
    "                    samples.extend(damage_samples)\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    def _apply_transforms(self, img: Image.Image, index: int) -> Image.Image:\n",
    "        \"\"\"Apply transforms to image.\"\"\"\n",
    "        if img.mode == \"L\":\n",
    "            img = img.point(lambda p: int(p * 255 / 4))\n",
    "        \n",
    "        if img.mode != \"RGB\":\n",
    "            img = img.convert(\"RGB\")\n",
    "        \n",
    "        img = TF.resize(img, [self.cfg.resolution, self.cfg.resolution], \n",
    "                       interpolation=TF.InterpolationMode.BICUBIC)\n",
    "        \n",
    "        if self.cfg.augment:\n",
    "            rng = np.random.RandomState(self.cfg.seed + index)\n",
    "            \n",
    "            # Horizontal flip (50% chance)\n",
    "            if rng.rand() < 0.5:\n",
    "                img = TF.hflip(img)\n",
    "            \n",
    "            # Random rotation 15 degrees (adds variety without affecting defect visibility)\n",
    "            if rng.rand() < 0.5:\n",
    "                angle = rng.uniform(-15, 15)\n",
    "                img = TF.rotate(img, angle, interpolation=TF.InterpolationMode.BILINEAR)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Dict[str, Any]:\n",
    "        sample_meta = self.samples[index]\n",
    "        img = Image.open(sample_meta[\"image_path\"])\n",
    "        original_size = img.size\n",
    "        original_mode = img.mode\n",
    "        \n",
    "        img = self._apply_transforms(img, index=index)\n",
    "        pixel_values = TF.to_tensor(img)\n",
    "        \n",
    "        if self.cfg.normalize_to_neg1_pos1:\n",
    "            pixel_values = pixel_values * 2.0 - 1.0\n",
    "        \n",
    "        class_id = None\n",
    "        if self.cfg.damage_type_to_class_id is not None:\n",
    "            damage_type = sample_meta[\"damage_type\"]\n",
    "            class_id = self.cfg.damage_type_to_class_id.get(damage_type, None)\n",
    "        \n",
    "        result = {\n",
    "            \"pixel_values\": pixel_values,\n",
    "            \"class_id\": class_id,\n",
    "            \"meta\": {\n",
    "                \"index\": index,\n",
    "                \"dataset_source\": sample_meta[\"dataset_source\"],\n",
    "                \"product_class\": sample_meta[\"product_class\"],\n",
    "                \"damage_type\": sample_meta[\"damage_type\"],\n",
    "                \"filename\": sample_meta[\"filename\"],\n",
    "                \"original_size\": original_size,\n",
    "                \"original_mode\": original_mode,\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "\n",
    "print(\"✓ Dataset class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e918a1",
   "metadata": {},
   "source": [
    "## Step 4: Training Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949e40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from diffusers import UNet2DConditionModel, AutoencoderKL, DDPMScheduler\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import warnings\n",
    "import json\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class DefectDiffusionTrainer:\n",
    "    \"\"\"Trainer for class-conditional defect generation with LR decay.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dir: str = \"./outputs\",\n",
    "        num_epochs: int = 100,\n",
    "        batch_size: int = 4,\n",
    "        learning_rate: float = 1e-4,\n",
    "        lora_rank: int = 8,\n",
    "        lora_alpha: int = 16,\n",
    "        device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    ):\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lora_rank = lora_rank\n",
    "        self.lora_alpha = lora_alpha\n",
    "        self.device = device\n",
    "        \n",
    "        # Track loss and config\n",
    "        self.loss_history = []\n",
    "        \n",
    "        # Determine LR schedule based on num_epochs\n",
    "        if num_epochs <= 100:\n",
    "            lr_schedule = f\"Constant {learning_rate} (augmentation enhancement)\"\n",
    "        else:\n",
    "            lr_schedule = f\"{learning_rate} (0-99), 5e-5 (100-174), 2e-5 (175+)\"\n",
    "        \n",
    "        self.config = {\n",
    "            \"num_epochs\": num_epochs,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"lora_rank\": lora_rank,\n",
    "            \"lora_alpha\": lora_alpha,\n",
    "            \"device\": str(device),\n",
    "            \"start_time\": datetime.now().isoformat(),\n",
    "            \"lr_decay_schedule\": lr_schedule\n",
    "        }\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\"INITIALIZING DEFECT DIFFUSION TRAINER V3\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Output directory: {self.output_dir}\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "        print(f\"Epochs: {num_epochs}\")\n",
    "        print(f\"Batch size: {batch_size}\")\n",
    "        print(f\"Learning rate: {learning_rate} (with decay)\")\n",
    "        print(f\"LoRA rank: {lora_rank}, alpha: {lora_alpha}\")\n",
    "        \n",
    "    def setup_models(self):\n",
    "        \"\"\"Load and configure all models.\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 1: Loading Models\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "        \n",
    "        print(\"Loading VAE...\")\n",
    "        self.vae = AutoencoderKL.from_pretrained(\n",
    "            model_id,\n",
    "            subfolder=\"vae\",\n",
    "            torch_dtype=torch.float32\n",
    "        ).to(self.device)\n",
    "        self.vae.requires_grad_(False)\n",
    "        self.vae.eval()\n",
    "        print(f\"VAE loaded (frozen)\")\n",
    "        \n",
    "        print(\"\\n Loading UNet...\")\n",
    "        self.unet = UNet2DConditionModel.from_pretrained(\n",
    "            model_id,\n",
    "            subfolder=\"unet\",\n",
    "            torch_dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "        print(\"Adding LoRA adapters...\")\n",
    "        lora_config = LoraConfig(\n",
    "            r=self.lora_rank,\n",
    "            lora_alpha=self.lora_alpha,\n",
    "            target_modules=[\"to_q\", \"to_k\", \"to_v\", \"to_out.0\"],\n",
    "            lora_dropout=0.1,\n",
    "            bias=\"none\",\n",
    "            init_lora_weights=True\n",
    "        )\n",
    "        \n",
    "        self.config.update({\n",
    "            \"lora_target_modules\": list(lora_config.target_modules),\n",
    "            \"lora_dropout\": lora_config.lora_dropout,\n",
    "            \"lora_scaling_factor\": lora_config.lora_alpha / lora_config.r,\n",
    "        })\n",
    "        \n",
    "        self.unet = get_peft_model(self.unet, lora_config)\n",
    "        self.unet.to(self.device)\n",
    "        \n",
    "        trainable_params = sum(p.numel() for p in self.unet.parameters() if p.requires_grad)\n",
    "        print(f\"UNet loaded with LoRA ({trainable_params/1e6:.2f}M trainable params)\")\n",
    "        \n",
    "        print(\"\\nCreating class embeddings...\")\n",
    "        self.class_embedder = nn.Embedding(\n",
    "            num_embeddings=4,\n",
    "            embedding_dim=768\n",
    "        ).to(self.device)\n",
    "        nn.init.normal_(self.class_embedder.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "        class_params = self.class_embedder.weight.numel()\n",
    "        print(f\"Class embeddings created ({class_params} params)\")\n",
    "        \n",
    "        self.config.update({\n",
    "            \"unet_lora_params\": trainable_params,\n",
    "            \"class_embedding_params\": class_params,\n",
    "            \"total_trainable_params\": trainable_params + class_params,\n",
    "        })\n",
    "        \n",
    "        print(\"\\nSetting up noise scheduler...\")\n",
    "        self.scheduler = DDPMScheduler(\n",
    "            num_train_timesteps=1000,\n",
    "            beta_start=0.00085,\n",
    "            beta_end=0.012,\n",
    "            beta_schedule=\"scaled_linear\",\n",
    "            clip_sample=False\n",
    "        )\n",
    "        print(f\"DDPM scheduler ready (1000 timesteps)\")\n",
    "        \n",
    "        print(f\"\\nTotal trainable parameters: {(trainable_params + class_params)/1e6:.2f}M\")\n",
    "        \n",
    "    def setup_data(self):\n",
    "        \"\"\"Setup bottle dataset and dataloader.\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 2: Loading Dataset\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        dataset_root = Path(\"./Defect_Spectrum\")\n",
    "        \n",
    "        self.damage_type_to_class_id = {\n",
    "            \"broken_large\": 0,\n",
    "            \"broken_small\": 1,\n",
    "            \"contamination\": 2,\n",
    "            \"good\": 3\n",
    "        }\n",
    "        \n",
    "        config = LocalDatasetConfig(\n",
    "            resolution=512,\n",
    "            augment=True,\n",
    "            seed=42,\n",
    "            normalize_to_neg1_pos1=True,\n",
    "            load_masks=False,\n",
    "            dataset_sources=[\"DS-MVTec\"],\n",
    "            product_classes=[\"bottle\"],\n",
    "            damage_types=None,\n",
    "            damage_type_to_class_id=self.damage_type_to_class_id\n",
    "        )\n",
    "        \n",
    "        self.dataset = DefectSpectrumLocalDataset(\n",
    "            root_dir=str(dataset_root),\n",
    "            cfg=config\n",
    "        )\n",
    "        \n",
    "        print(f\"Dataset loaded: {len(self.dataset)} samples\")\n",
    "        \n",
    "        class_counts = {i: 0 for i in range(4)}\n",
    "        for i in range(len(self.dataset)):\n",
    "            class_id = self.dataset[i][\"class_id\"]\n",
    "            class_counts[class_id] += 1\n",
    "        \n",
    "        print(\"\\nSamples per class:\")\n",
    "        for class_id, count in sorted(class_counts.items()):\n",
    "            damage_type = [k for k, v in self.damage_type_to_class_id.items() if v == class_id][0]\n",
    "            print(f\"  Class {class_id} ({damage_type:15s}): {count} samples\")\n",
    "        \n",
    "        self.config.update({\n",
    "            \"dataset_size\": len(self.dataset),\n",
    "            \"dataset_sources\": [\"DS-MVTec\"],\n",
    "            \"product_classes\": [\"bottle\"],\n",
    "            \"resolution\": 512,\n",
    "            \"augmentation\": True,\n",
    "            \"damage_types\": list(self.damage_type_to_class_id.keys()),\n",
    "            \"class_distribution\": {str(self.damage_type_to_class_id[k]): v for k, v in \n",
    "                                  [(k, class_counts[self.damage_type_to_class_id[k]]) \n",
    "                                   for k in self.damage_type_to_class_id.keys()]},\n",
    "        })\n",
    "        \n",
    "        self.dataloader = DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=True if self.device == \"cuda\" else False\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nDataLoader created: {len(self.dataloader)} batches per epoch\")\n",
    "        \n",
    "    def setup_optimizer(self):\n",
    "        \"\"\"Setup optimizer for joint training.\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 3: Setting Up Optimizer\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        trainable_params = list(self.unet.parameters()) + list(self.class_embedder.parameters())\n",
    "        trainable_params = [p for p in trainable_params if p.requires_grad]\n",
    "        \n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            trainable_params,\n",
    "            lr=self.learning_rate,\n",
    "            betas=(0.9, 0.999),\n",
    "            weight_decay=0.01\n",
    "        )\n",
    "        \n",
    "        self.config.update({\n",
    "            \"optimizer\": \"AdamW\",\n",
    "            \"optimizer_betas\": [0.9, 0.999],\n",
    "            \"optimizer_weight_decay\": 0.01,\n",
    "        })\n",
    "        \n",
    "        print(f\" AdamW optimizer configured\")\n",
    "        print(f\" Learning rate: {self.learning_rate}\")\n",
    "        print(f\" Trainable parameters: {sum(p.numel() for p in trainable_params)/1e6:.2f}M\")\n",
    "        \n",
    "    def train_epoch(self, epoch: int):\n",
    "        \"\"\"Train for one epoch.\"\"\"\n",
    "        \n",
    "        self.unet.train()\n",
    "        self.class_embedder.train()\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        progress_bar = tqdm(self.dataloader, desc=f\"Epoch {epoch+1}/{self.num_epochs}\")\n",
    "        \n",
    "        for batch_idx, batch in enumerate(progress_bar):\n",
    "            images = batch[\"pixel_values\"].to(self.device)\n",
    "            class_ids = batch[\"class_id\"].to(self.device)\n",
    "            \n",
    "            class_embeddings = self.class_embedder(class_ids)\n",
    "            class_embeddings = class_embeddings.unsqueeze(1)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                latents = self.vae.encode(images).latent_dist.sample()\n",
    "                latents = latents * 0.18215\n",
    "            \n",
    "            noise = torch.randn_like(latents)\n",
    "            timesteps = torch.randint(\n",
    "                0, self.scheduler.config.num_train_timesteps,\n",
    "                (images.shape[0],),\n",
    "                device=self.device\n",
    "            ).long()\n",
    "            \n",
    "            noisy_latents = self.scheduler.add_noise(latents, noise, timesteps)\n",
    "            \n",
    "            noise_pred = self.unet(\n",
    "                noisy_latents,\n",
    "                timesteps,\n",
    "                encoder_hidden_states=class_embeddings\n",
    "            ).sample\n",
    "            \n",
    "            loss = F.mse_loss(noise_pred, noise)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "        \n",
    "        avg_loss = epoch_loss / len(self.dataloader)\n",
    "        return avg_loss\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def validate(self, epoch: int):\n",
    "        \"\"\"Generate validation samples with fixed seeds.\"\"\"\n",
    "        \n",
    "        print(f\"\\nGenerating validation samples (epoch {epoch+1})...\")\n",
    "        \n",
    "        self.unet.eval()\n",
    "        self.class_embedder.eval()\n",
    "        \n",
    "        num_samples_per_class = 5\n",
    "        \n",
    "        for class_id in range(4):\n",
    "            class_ids = torch.full((num_samples_per_class,), class_id, device=self.device)\n",
    "            class_embeddings = self.class_embedder(class_ids).unsqueeze(1)\n",
    "            \n",
    "            # Fixed seed for reproducible validation\n",
    "            torch.manual_seed(42 + class_id + epoch)\n",
    "            latents = torch.randn(\n",
    "                num_samples_per_class, 4, 64, 64,\n",
    "                device=self.device\n",
    "            )\n",
    "            \n",
    "            self.scheduler.set_timesteps(50)\n",
    "            \n",
    "            for t in self.scheduler.timesteps:\n",
    "                timesteps = torch.full((num_samples_per_class,), t, device=self.device).long()\n",
    "                \n",
    "                noise_pred = self.unet(\n",
    "                    latents,\n",
    "                    timesteps,\n",
    "                    encoder_hidden_states=class_embeddings\n",
    "                ).sample\n",
    "                \n",
    "                latents = self.scheduler.step(noise_pred, t, latents).prev_sample\n",
    "            \n",
    "            latents = latents / 0.18215\n",
    "            images = self.vae.decode(latents).sample\n",
    "            \n",
    "            images = (images / 2 + 0.5).clamp(0, 1)\n",
    "            images = images.cpu().permute(0, 2, 3, 1).numpy()\n",
    "            images = (images * 255).astype(np.uint8)\n",
    "            \n",
    "            damage_type = [k for k, v in self.damage_type_to_class_id.items() if v == class_id][0]\n",
    "            \n",
    "            for i, img in enumerate(images):\n",
    "                img_pil = Image.fromarray(img)\n",
    "                save_path = self.output_dir / f\"epoch{epoch+1:03d}_class{class_id}_{damage_type}_{i}.png\"\n",
    "                img_pil.save(save_path)\n",
    "        \n",
    "        print(f\" Validation samples saved to {self.output_dir}\")\n",
    "    \n",
    "    def save_checkpoint(self, epoch: int):\n",
    "        \"\"\"Save model checkpoint.\"\"\"\n",
    "        \n",
    "        checkpoint_path = self.output_dir / f\"checkpoint_epoch{epoch+1:03d}.pt\"\n",
    "        \n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"unet_state_dict\": self.unet.state_dict(),\n",
    "            \"class_embedder_state_dict\": self.class_embedder.state_dict(),\n",
    "            \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "            \"damage_type_to_class_id\": self.damage_type_to_class_id,\n",
    "            \"loss_history\": self.loss_history,\n",
    "            \"config\": self.config,\n",
    "        }, checkpoint_path)\n",
    "        \n",
    "        print(f\" Checkpoint saved: {checkpoint_path}\")\n",
    "    \n",
    "    def save_config(self):\n",
    "        \"\"\"Save training configuration to JSON.\"\"\"\n",
    "        \n",
    "        config_path = self.output_dir / \"training_config.json\"\n",
    "        \n",
    "        self.config.update({\n",
    "            \"total_epochs_trained\": len(self.loss_history),\n",
    "            \"final_loss\": self.loss_history[-1] if self.loss_history else None,\n",
    "            \"min_loss\": min(self.loss_history) if self.loss_history else None,\n",
    "            \"max_loss\": max(self.loss_history) if self.loss_history else None,\n",
    "            \"end_time\": datetime.now().isoformat(),\n",
    "        })\n",
    "        \n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump(self.config, f, indent=2)\n",
    "        \n",
    "        print(f\" Config saved: {config_path}\")\n",
    "    \n",
    "    def save_loss_history(self):\n",
    "        \"\"\"Save loss history to CSV and plot.\"\"\"\n",
    "        \n",
    "        csv_path = self.output_dir / \"loss_history.csv\"\n",
    "        with open(csv_path, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['Epoch', 'Loss'])\n",
    "            for epoch, loss in enumerate(self.loss_history, 1):\n",
    "                writer.writerow([epoch, loss])\n",
    "        \n",
    "        print(f\" Loss history saved: {csv_path}\")\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, len(self.loss_history) + 1), self.loss_history, \n",
    "                marker='o', linewidth=2, markersize=4, color='#2E86AB')\n",
    "        plt.xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "        plt.ylabel('Average Loss (MSE)', fontsize=12, fontweight='bold')\n",
    "        plt.title('Training Loss Over Time', fontsize=14, fontweight='bold')\n",
    "        plt.grid(True, alpha=0.3, linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plot_path = self.output_dir / \"loss_curve.png\"\n",
    "        plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\" Loss plot saved: {plot_path}\")\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Full training loop with learning rate decay.\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STEP 4: Training\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            # Learning rate decay schedule\n",
    "            if epoch == 100 and self.num_epochs > 100:\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr'] = 5e-5\n",
    "                print(f\" Learning rate reduced to 5e-5 (epoch 100)\")\n",
    "            elif epoch == 175 and self.num_epochs > 100:\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr'] = 2e-5\n",
    "                print(f\" Learning rate reduced to 2e-5 (epoch 175)\")\n",
    "            \n",
    "            avg_loss = self.train_epoch(epoch)\n",
    "            self.loss_history.append(avg_loss)\n",
    "            print(f\"\\nEpoch {epoch+1}/{self.num_epochs} - Average Loss: {avg_loss:.4f}\")\n",
    "            \n",
    "            if (epoch + 1) % 25 == 0:\n",
    "                self.validate(epoch)\n",
    "            \n",
    "            if (epoch + 1) % 25 == 0:\n",
    "                self.save_checkpoint(epoch)\n",
    "        \n",
    "        # Save final checkpoint\n",
    "        self.save_checkpoint(self.num_epochs - 1)\n",
    "        \n",
    "        # Save training artifacts\n",
    "        self.save_loss_history()\n",
    "        self.save_config()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"TRAINING COMPLETE!\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"Final loss: {self.loss_history[-1]:.4f}\")\n",
    "        print(f\"Min loss: {min(self.loss_history):.4f} at epoch {self.loss_history.index(min(self.loss_history))+1}\")\n",
    "        print(f\"Outputs saved to: {self.output_dir}\")\n",
    "\n",
    "print(\"Trainer class defined with LR decay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f7e329",
   "metadata": {},
   "source": [
    "## Step 5: Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd20a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d40fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer - train from scratch with early LR decay\n",
    "trainer = DefectDiffusionTrainer(\n",
    "    output_dir=\"./outputs/bottle_diffusion\",\n",
    "    num_epochs=250,\n",
    "    batch_size=4,        # 4 for T4 GPU\n",
    "    learning_rate=1e-4,\n",
    "    lora_rank=16,        # Use rank=16 for better capacity\n",
    "    lora_alpha=32,       # Maintain 2.0 scaling factor\n",
    ")\n",
    "\n",
    "# Setup everything\n",
    "trainer.setup_models()\n",
    "trainer.setup_data()\n",
    "trainer.setup_optimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398fb8ca",
   "metadata": {},
   "source": [
    "## Step 6: View Results\n",
    "\n",
    "Check generated samples and loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc67aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display loss curve\n",
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "# Show loss curve\n",
    "if Path('outputs/bottle_diffusion/loss_curve.png').exists():\n",
    "    print(\"Training Loss Curve:\")\n",
    "    display(Image('outputs/bottle_diffusion/loss_curve.png'))\n",
    "\n",
    "# Show latest validation images (now 5 per class)\n",
    "images = sorted(glob.glob('outputs/bottle_diffusion/epoch250*.png'))\n",
    "if images:\n",
    "    print(f\"\\nFinal epoch validation samples ({len(images)} images):\")\n",
    "    print(\"Showing first 20 (5 per class × 4 classes):\")\n",
    "    for img_path in images[:20]:\n",
    "        print(Path(img_path).name)\n",
    "        display(Image(img_path, width=250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb333edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View training config\n",
    "import json\n",
    "\n",
    "config_path = 'outputs/bottle_diffusion/training_config.json'\n",
    "if Path(config_path).exists():\n",
    "    with open(config_path) as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    print(\"Training Configuration:\")\n",
    "    print(\"=\" * 50)\n",
    "    for key, value in config.items():\n",
    "        print(f\"{key:30s}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d055e9",
   "metadata": {},
   "source": [
    "## Step 7: Download Results\n",
    "\n",
    "Download only essentials: final checkpoint, config, loss data, and validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514708f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download final checkpoint only\n",
    "print(\"Downloading final checkpoint...\")\n",
    "files.download('outputs/bottle_diffusion/checkpoint_epoch250.pt')\n",
    "\n",
    "# Download training artifacts\n",
    "print(\"\\nDownloading training config and loss data...\")\n",
    "files.download('outputs/bottle_diffusion/training_config.json')\n",
    "files.download('outputs/bottle_diffusion/loss_history.csv')\n",
    "files.download('outputs/bottle_diffusion/loss_curve.png')\n",
    "\n",
    "# Zip validation images\n",
    "print(\"\\nPreparing validation images...\")\n",
    "!zip -r validation_images.zip outputs/bottle_diffusion/epoch*.png\n",
    "files.download('validation_images.zip')\n",
    "\n",
    "print(\"\\n Downloads complete:\")\n",
    "print(\"  - checkpoint_epoch250.pt (final model)\")\n",
    "print(\"  - training_config.json (hyperparameters + LR schedule)\")\n",
    "print(\"  - loss_history.csv (per-epoch loss)\")\n",
    "print(\"  - loss_curve.png (loss visualization)\")\n",
    "print(\"  - validation_images.zip (all validation images - 5 per class)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
